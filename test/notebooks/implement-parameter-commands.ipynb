{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "File: '../../src/streamUtils.ts'\n",
      "```\n",
      " import axios, { AxiosResponse } from \"axios\";\n",
      "import { CreateChatCompletionResponse } from \"openai\";\n",
      "import { CancellationToken, window } from \"vscode\";\n",
      "import { FinishReason } from \"./finishReason\";\n",
      "\n",
      "export async function* streamChatCompletion(\n",
      "  response: AxiosResponse<CreateChatCompletionResponse, AsyncIterable<Buffer>>,\n",
      "  token: CancellationToken\n",
      "): AsyncGenerator<string | FinishReason, void, undefined> {\n",
      "  // types are unfortunately not well defined so we have to cast to unknown first to get an AsyncIterable<T>\n",
      "  const dataStream = response.data as unknown as AsyncIterable<Buffer>;\n",
      "\n",
      "  for await (const chunk of dataStream) {\n",
      "    if (token.isCancellationRequested) {\n",
      "      throw new axios.Cancel(\"ChatCompletion API request cancelled by user\");\n",
      "    }\n",
      "\n",
      "    const lines = chunk\n",
      "      .toString(\"utf8\")\n",
      "      .split(\"\\n\")\n",
      "      .filter((line) => line.trim().startsWith(\"data: \"));\n",
      "\n",
      "    for (const line of lines) {\n",
      "      const message = line.replace(/^data: /, \"\");\n",
      "      const json = JSON.parse(message);\n",
      "\n",
      "      const content = json.choices[0].delta.content;\n",
      "\n",
      "      if (content !== undefined && content !== \"\") {\n",
      "        yield content;\n",
      "      }\n",
      "\n",
      "      const finishReason = json.choices[0].finish_reason;\n",
      "\n",
      "      switch (finishReason) {\n",
      "        case \"length\": // Incomplete model output due to max_tokens parameter or token limit\n",
      "          yield FinishReason.length;\n",
      "\n",
      "        case \"content_filter\": // Omitted content due to a flag from OpenAI content filters\n",
      "        yield FinishReason.contentFilter;\n",
      "\n",
      "        case \"stop\": // API returned complete model output.\n",
      "          yield FinishReason.stop;\n",
      "          return;\n",
      "        case null:\n",
      "        case undefined:\n",
      "        case \"null\": // API response still in progress or incomplete\n",
      "          continue;\n",
      "        default: // API returned a stop_reason unknown to us\n",
      "          throw new Error(\"Unhandled stop_reason:\" + finishReason);\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "export async function* bufferWholeChunks(\n",
      "  stream: AsyncGenerator<string | FinishReason, void, undefined>\n",
      "): AsyncGenerator<string | FinishReason, void, undefined> {\n",
      "  let buffer = \"\";\n",
      "  let value: string | void | FinishReason = undefined;\n",
      "\n",
      "  while ((value = (await stream.next()).value)) {\n",
      "    if (\n",
      "      typeof value === \"string\" &&\n",
      "      !value.includes(\"\\n\") &&\n",
      "      !value.includes(\" \") &&\n",
      "      !value.includes(\"-\") &&\n",
      "      !value.includes(\"<\") &&\n",
      "      !value.includes(\">\") &&\n",
      "      !value.includes(\"(\") &&\n",
      "      !value.includes(\")\") &&\n",
      "      !value.includes(\",\") &&\n",
      "      !value.includes(\".\") &&\n",
      "      !value.includes(\"'\") &&\n",
      "      !value.includes('\"')\n",
      "    ) {\n",
      "      buffer += value;\n",
      "    } else {\n",
      "      if (buffer.length > 0) {\n",
      "        if (typeof value === \"string\") {\n",
      "          yield buffer + value;\n",
      "        } else {\n",
      "          if (buffer !== \"\") {\n",
      "            yield buffer;\n",
      "          }\n",
      "          yield value;\n",
      "        }\n",
      "        buffer = \"\";\n",
      "      } else {\n",
      "        yield value;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/cellUtils.ts'\n",
      "```\n",
      " import {\n",
      "  ChatCompletionRequestMessage,\n",
      "  ChatCompletionRequestMessageRoleEnum,\n",
      "} from \"openai\";\n",
      "import {\n",
      "  NotebookCellKind,\n",
      "  NotebookEdit,\n",
      "  NotebookEditor,\n",
      "  NotebookRange,\n",
      "  Range,\n",
      "  WorkspaceEdit,\n",
      "  commands,\n",
      "  languages,\n",
      "  window,\n",
      "  workspace,\n",
      "} from \"vscode\";\n",
      "import { CompletionType } from \"./completionType\";\n",
      "\n",
      "const ADDITIONAL_PROMPT_INFO_MESSAGE =\n",
      "  \"Select any additional information you want to include in the prompt\";\n",
      "\n",
      "export async function appendTextToCell(\n",
      "  editor: NotebookEditor,\n",
      "  cellIndex: number,\n",
      "  textToken: string\n",
      ") {\n",
      "  const existingCell = editor.notebook.cellAt(cellIndex);\n",
      "\n",
      "  // If the cell is empty, it doesn't make sense to add any superfluous linebreaks, tabs or whitespaces\n",
      "  if (existingCell.document.getText().length === 0 && !/\\S/.test(textToken)) {\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  if (textToken.startsWith(\"\\n\")) {\n",
      "    // we check if this is an empty cell. In that case, it doesn't make sense to start with a line break\n",
      "    if (existingCell.document.positionAt(1).character === 0) {\n",
      "      // we might have received a little more than just a linebreak, so we keep the remaining text and this function continue. Otherwise, we skip completly.\n",
      "      if (textToken.length > 1) {\n",
      "        textToken = textToken.substring(1);\n",
      "      } else {\n",
      "        return;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  const edit = new WorkspaceEdit();\n",
      "  edit.insert(\n",
      "    existingCell.document.uri,\n",
      "    existingCell.document.positionAt(9999999999),\n",
      "    textToken\n",
      "  );\n",
      "  await workspace.applyEdit(edit);\n",
      "}\n",
      "\n",
      "export async function insertCell(\n",
      "  editor: NotebookEditor,\n",
      "  cellIndex: number,\n",
      "  cellKind: NotebookCellKind,\n",
      "  languageId: string\n",
      ") {\n",
      "  // Whenever we insert a cell, we remove any superfluous linebreaks in the previous cell\n",
      "  const existingCell = editor.notebook.cellAt(cellIndex);\n",
      "  if (existingCell.document.getText().endsWith(\"\\n\")) {\n",
      "    const edit = new WorkspaceEdit();\n",
      "    const lastLineRange = existingCell.document.validateRange(\n",
      "      new Range(\n",
      "        existingCell.document.lineCount - 2,\n",
      "        9999999999,\n",
      "        existingCell.document.lineCount,\n",
      "        0\n",
      "      )\n",
      "    );\n",
      "\n",
      "    edit.delete(existingCell.document.uri, lastLineRange);\n",
      "    await workspace.applyEdit(edit);\n",
      "  }\n",
      "\n",
      "  await commands.executeCommand(\"notebook.cell.quitEdit\");\n",
      "\n",
      "  if (cellKind === NotebookCellKind.Code && languageId === \"python\") {\n",
      "    await commands.executeCommand(\"notebook.cell.insertCodeCellBelow\", [\n",
      "      { index: cellIndex },\n",
      "    ]);\n",
      "  } else {\n",
      "    await commands.executeCommand(\"notebook.cell.insertMarkdownCellBelow\", [\n",
      "      { index: cellIndex },\n",
      "    ]);\n",
      "  }\n",
      "\n",
      "  cellIndex++;\n",
      "\n",
      "  const edit = new WorkspaceEdit();\n",
      "  let cell = editor.notebook.cellAt(cellIndex);\n",
      "  edit.set(cell.notebook.uri, [\n",
      "    NotebookEdit.updateCellMetadata(cell.index, {\n",
      "      custom: { metadata: { tags: [\"assistant\"] } },\n",
      "    }),\n",
      "  ]);\n",
      "  await workspace.applyEdit(edit);\n",
      "\n",
      "  return cellIndex;\n",
      "}\n",
      "\n",
      "export async function convertCellsToMessages(\n",
      "  cellIndex: number,\n",
      "  completionType: CompletionType\n",
      "): Promise<ChatCompletionRequestMessage[]> {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  const notebook = editor.notebook;\n",
      "\n",
      "  const startCellIndex =\n",
      "    completionType === CompletionType.currentCellAndAbove ? 0 : cellIndex;\n",
      "\n",
      "  const diagnostics = languages\n",
      "    .getDiagnostics()\n",
      "    .filter(([uri]) => uri.path === notebook.uri.path)\n",
      "    .flatMap(([, diag]) => diag);\n",
      "\n",
      "  const cellInfos = notebook\n",
      "    .getCells(new NotebookRange(startCellIndex, cellIndex + 1))\n",
      "    .map((cell) => {\n",
      "      const problems = diagnostics.filter(\n",
      "        (d) => cell.document.validateRange(d.range) === d.range\n",
      "      );\n",
      "      const nonImgOutputs = cell.outputs\n",
      "        .flatMap((o) => o.items.filter((i) => !i.mime.startsWith(\"image\")))\n",
      "        .map((i) => i.data.toString());\n",
      "      return { cell, problems, nonImgOutputs };\n",
      "    });\n",
      "\n",
      "  const addProblemsOption = `Add Problems (${cellInfos.reduce(\n",
      "    (a, c) => a + c.problems.length,\n",
      "    0\n",
      "  )})`;\n",
      "  const addOutputsOption = `Add Outputs (${cellInfos.reduce(\n",
      "    (a, c) => a + c.nonImgOutputs.length,\n",
      "    0\n",
      "  )})`;\n",
      "\n",
      "  const options = cellInfos.some((c) => c.problems.length)\n",
      "    ? [addProblemsOption]\n",
      "    : [];\n",
      "\n",
      "  if (cellInfos.some((c) => c.nonImgOutputs.length)) {\n",
      "    options.push(addOutputsOption);\n",
      "  }\n",
      "\n",
      "  var messages: ChatCompletionRequestMessage[] = [];\n",
      "  const selectedOptions =\n",
      "    options.length > 0\n",
      "      ? await window.showQuickPick(options, {\n",
      "          placeHolder: ADDITIONAL_PROMPT_INFO_MESSAGE,\n",
      "          canPickMany: true,\n",
      "        })\n",
      "      : [];\n",
      "\n",
      "  cellInfos.forEach(({ cell, problems, nonImgOutputs }) => {\n",
      "    let role: ChatCompletionRequestMessageRoleEnum =\n",
      "      ChatCompletionRequestMessageRoleEnum.User;\n",
      "    const tags: string[] = cell.metadata?.custom?.metadata?.tags;\n",
      "\n",
      "    if (tags && tags.length > 0) {\n",
      "      role = tags[0] as ChatCompletionRequestMessageRoleEnum;\n",
      "    }\n",
      "\n",
      "    messages.push({ role: role, content: cell.document.getText() });\n",
      "\n",
      "    if (\n",
      "      problems.length &&\n",
      "      selectedOptions?.some((x) => x.includes(addProblemsOption))\n",
      "    ) {\n",
      "      messages.push({\n",
      "        role: role ?? \"user\",\n",
      "        content:\n",
      "          \"Problems reported by VSCode from previous code:\\n\" +\n",
      "          problems.map((p) => `${p.code}: ${p.message}`),\n",
      "      });\n",
      "    }\n",
      "\n",
      "    if (\n",
      "      nonImgOutputs.length &&\n",
      "      selectedOptions?.some((x) => x.includes(addOutputsOption))\n",
      "    ) {\n",
      "      nonImgOutputs.forEach((output) =>\n",
      "        messages.push({\n",
      "          role: role ?? \"user\",\n",
      "          content: \"Output from previous code:\\n\" + output,\n",
      "        })\n",
      "      );\n",
      "    }\n",
      "  });\n",
      "\n",
      "  const totalLengthUserMessages = messages.reduce(\n",
      "    (accumulator, currentValue) => {\n",
      "      return accumulator + currentValue.content.length;\n",
      "    },\n",
      "    0\n",
      "  );\n",
      "\n",
      "  const systemMessages = messages.filter(\n",
      "    (m) => m.role === ChatCompletionRequestMessageRoleEnum.System\n",
      "  );\n",
      "\n",
      "  // We only add a system message if none was defined\n",
      "  // When the user's input is very short, the large language model tend to pay too much attention to the system message and starts to speak about it, which is confusing for the user. Empirically, length 32 seems to be a good threshold to avoid this.\n",
      "  if (systemMessages.length === 0 && totalLengthUserMessages > 32) {\n",
      "    messages.push({\n",
      "      role: ChatCompletionRequestMessageRoleEnum.System,\n",
      "      content:\n",
      "        \"Format your answer as markdown. If you include a markdown code block, specify the language.\",\n",
      "    });\n",
      "  }\n",
      "\n",
      "  return messages;\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/completionType.ts'\n",
      "```\n",
      " export enum CompletionType {\n",
      "  currentCellAndAbove,\n",
      "  currentCell\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/uiProgress.ts'\n",
      "```\n",
      " import { Progress } from \"vscode\";\n",
      "\n",
      "export type UIProgress = Progress<{\n",
      "  message?: string | undefined;\n",
      "  increment?: number | undefined;\n",
      "}>;\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/finishReason.ts'\n",
      "```\n",
      " export enum FinishReason {\n",
      "  length,\n",
      "  contentFilter,\n",
      "  stop,\n",
      "  null\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/extension.ts'\n",
      "```\n",
      " import axios from \"axios\";\n",
      "import {\n",
      "  ExtensionContext,\n",
      "  NotebookEdit,\n",
      "  NotebookRange,\n",
      "  ProgressLocation,\n",
      "  WorkspaceEdit,\n",
      "  commands,\n",
      "  window,\n",
      "  workspace,\n",
      "} from \"vscode\";\n",
      "import { generateCompletion } from \"./completion\";\n",
      "import { CompletionType } from \"./completionType\";\n",
      "import { FinishReason } from \"./finishReason\";\n",
      "\n",
      "const GENERATING_NEXT_CELL = \"Generating next cell(s)...\";\n",
      "const COMPLETION_COMPLETED = \"Cell generation completed\";\n",
      "const COMPLETION_CANCELLED = \"Generation cancelled\";\n",
      "const COMPLETION_FAILED = \"Failed to generate new cell(s)\";\n",
      "\n",
      "export async function activate(context: ExtensionContext) {\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\n",
      "      \"notebook-chatcompletion.sendCellAndAbove\",\n",
      "      (...args) => generateCells(args, CompletionType.currentCellAndAbove)\n",
      "    )\n",
      "  );\n",
      "\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\"notebook-chatcompletion.sendCell\", (...args) =>\n",
      "      generateCells(args, CompletionType.currentCell)\n",
      "    )\n",
      "  );\n",
      "\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\n",
      "      \"notebook-chatcompletion.setRoleAssistant\",\n",
      "      setRoleAssistant\n",
      "    )\n",
      "  );\n",
      "\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\n",
      "      \"notebook-chatcompletion.setRoleSystem\",\n",
      "      setRoleSystem\n",
      "    )\n",
      "  );\n",
      "\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\"notebook-chatcompletion.setModel\", setModel)\n",
      "  );\n",
      "  context.subscriptions.push(\n",
      "    commands.registerCommand(\n",
      "      \"notebook-chatcompletion.setTemperature\",\n",
      "      setTemperature\n",
      "    )\n",
      "  );\n",
      "}\n",
      "\n",
      "function getErrorMessage(error: unknown) {\n",
      "  if (error instanceof Error) {\n",
      "    return error.message;\n",
      "  }\n",
      "  return String(error);\n",
      "}\n",
      "\n",
      "async function generateCells(args: any, completionType: CompletionType) {\n",
      "  let cellIndex = args[0]?.index;\n",
      "\n",
      "  if (!cellIndex) {\n",
      "    cellIndex = window.activeNotebookEditor!.selection.end - 1;\n",
      "  }\n",
      "\n",
      "  window.activeNotebookEditor!.selection = new NotebookRange(\n",
      "    cellIndex,\n",
      "    cellIndex\n",
      "  );\n",
      "\n",
      "  window.withProgress(\n",
      "    {\n",
      "      title: GENERATING_NEXT_CELL,\n",
      "      location: ProgressLocation.Notification,\n",
      "      cancellable: true,\n",
      "    },\n",
      "    async function (progress, token) {\n",
      "      try {\n",
      "        let finishReason = FinishReason.null;\n",
      "\n",
      "        while (\n",
      "          finishReason === FinishReason.null ||\n",
      "          finishReason === FinishReason.length\n",
      "        ) {\n",
      "          finishReason = await generateCompletion(\n",
      "            cellIndex,\n",
      "            completionType,\n",
      "            progress,\n",
      "            token,\n",
      "            finishReason\n",
      "          );\n",
      "        }\n",
      "\n",
      "        // we are done editing any cell, so we close edit mode\n",
      "        await commands.executeCommand(\"notebook.cell.quitEdit\");\n",
      "\n",
      "        switch (finishReason) {\n",
      "          case FinishReason.stop:\n",
      "            // report success\n",
      "            window.showInformationMessage(COMPLETION_COMPLETED);\n",
      "            progress.report({ increment: 100 });\n",
      "            break;\n",
      "\n",
      "          case FinishReason.contentFilter:\n",
      "            // report content policy violation\n",
      "            window.showErrorMessage(\n",
      "              \"API finished early due to content policy violation\"\n",
      "            );\n",
      "            progress.report({ increment: 100 });\n",
      "            break;\n",
      "\n",
      "          default:\n",
      "            throw new Error(\"Invalid state: finish_reason wasn't handled.\");\n",
      "        }\n",
      "      } catch (error: any) {\n",
      "        if (error instanceof axios.Cancel) {\n",
      "          // report cancellation\n",
      "          window.showInformationMessage(\n",
      "            `${COMPLETION_CANCELLED}: ${error.message}`\n",
      "          );\n",
      "        } else {\n",
      "          // report error\n",
      "          window.showErrorMessage(`${COMPLETION_FAILED}: ${error.message}`, {\n",
      "            detail: getErrorMessage(error),\n",
      "            modal: true,\n",
      "          });\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  );\n",
      "}\n",
      "\n",
      "async function setModel() {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  let model = await window.showQuickPick(\n",
      "    [\n",
      "      \"gpt-4\",\n",
      "      \"gpt-4-0314\",\n",
      "      \"gpt-4-32k\",\n",
      "      \"gpt-4-32k-0314\",\n",
      "      \"gpt-3.5-turbo\",\n",
      "      \"gpt-3.5-turbo-0301\",\n",
      "      \"other\",\n",
      "    ],\n",
      "    {\n",
      "      placeHolder: \"Select the model:\",\n",
      "    }\n",
      "  );\n",
      "\n",
      "  if (model === \"other\") {\n",
      "    model = await window.showInputBox({\n",
      "      prompt: \"Enter the model name:\",\n",
      "      validateInput: (value) =>\n",
      "        value.trim().length > 0 ? null : \"Model name cannot be empty\",\n",
      "    });\n",
      "  }\n",
      "\n",
      "  if (model) {\n",
      "    const edit = new WorkspaceEdit();\n",
      "    edit.set(editor.notebook.uri, [\n",
      "      NotebookEdit.updateNotebookMetadata({\n",
      "        custom: { ...editor.notebook.metadata.custom, model: model },\n",
      "      }),\n",
      "    ]);\n",
      "    await workspace.applyEdit(edit);\n",
      "  }\n",
      "}\n",
      "\n",
      "export async function setTemperature() {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  const temperature = await window.showInputBox({\n",
      "    prompt: \"Enter the temperature value (0-1):\",\n",
      "    validateInput: (value) =>\n",
      "      parseFloat(value) >= 0 && parseFloat(value) <= 1\n",
      "        ? null\n",
      "        : \"Temperature must be between 0 and 1\",\n",
      "  });\n",
      "\n",
      "  if (temperature) {\n",
      "    const edit = new WorkspaceEdit();\n",
      "    edit.set(editor.notebook.uri, [\n",
      "      NotebookEdit.updateNotebookMetadata({\n",
      "        custom: {\n",
      "          ...editor.notebook.metadata.custom,\n",
      "          temperature: parseFloat(temperature),\n",
      "        },\n",
      "      }),\n",
      "    ]);\n",
      "    await workspace.applyEdit(edit);\n",
      "  }\n",
      "}\n",
      "\n",
      "async function setRoleAssistant() {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  const cellIndex = editor.selection.end - 1;\n",
      "  const cell = editor.notebook.cellAt(cellIndex);\n",
      "\n",
      "  const edit = new WorkspaceEdit();\n",
      "  edit.set(cell.notebook.uri, [\n",
      "    NotebookEdit.updateCellMetadata(cell.index, {\n",
      "      custom: { metadata: { tags: [\"assistant\"] } },\n",
      "    }),\n",
      "  ]);\n",
      "  await workspace.applyEdit(edit);\n",
      "}\n",
      "\n",
      "async function setRoleSystem() {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  const cellIndex = editor.selection.end - 1;\n",
      "  const cell = editor.notebook.cellAt(cellIndex);\n",
      "\n",
      "  const edit = new WorkspaceEdit();\n",
      "  edit.set(cell.notebook.uri, [\n",
      "    NotebookEdit.updateCellMetadata(cell.index, {\n",
      "      custom: { metadata: { tags: [\"system\"] } },\n",
      "    }),\n",
      "  ]);\n",
      "  await workspace.applyEdit(edit);\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../src/completion.ts'\n",
      "```\n",
      " import axios from \"axios\";\n",
      "import { Configuration, OpenAIApi } from \"openai\";\n",
      "import {\n",
      "  CancellationToken,\n",
      "  ConfigurationTarget,\n",
      "  NotebookCellKind,\n",
      "  NotebookEdit,\n",
      "  NotebookRange,\n",
      "  WorkspaceEdit,\n",
      "  window,\n",
      "  workspace,\n",
      "} from \"vscode\";\n",
      "import {\n",
      "  appendTextToCell,\n",
      "  convertCellsToMessages,\n",
      "  insertCell,\n",
      "} from \"./cellUtils\";\n",
      "import { CompletionType } from \"./completionType\";\n",
      "import { FinishReason } from \"./finishReason\";\n",
      "import { bufferWholeChunks, streamChatCompletion } from \"./streamUtils\";\n",
      "import { UIProgress } from \"./uiProgress\";\n",
      "\n",
      "export const SENDING_COMPLETION_REQUEST = \"Sending ChatCompletion request\";\n",
      "export const RECEIVING_TOKENS = \"Receiving tokens...\";\n",
      "const pythonCodeBlockStart = \"```python\\n\";\n",
      "const codeBlockEnd = \"```\";\n",
      "\n",
      "export const output = window.createOutputChannel(\"Notebook ChatCompletion\");\n",
      "\n",
      "export async function generateCompletion(\n",
      "  cellIndex: number,\n",
      "  completionType: CompletionType,\n",
      "  progress: UIProgress,\n",
      "  token: CancellationToken,\n",
      "  previousFinishReason: FinishReason\n",
      "): Promise<FinishReason> {\n",
      "  const editor = window.activeNotebookEditor!;\n",
      "  const notebookMetadata = editor.notebook.metadata.custom;\n",
      "  const temperature = notebookMetadata?.temperature ?? 0;\n",
      "  const model = notebookMetadata?.model ?? \"gpt-4\";\n",
      "\n",
      "  const messages = await convertCellsToMessages(cellIndex, completionType);\n",
      "  let currentKind: NotebookCellKind | undefined = undefined;\n",
      "\n",
      "  // If the generation was previously interrupted, we need to nudge the prompt\n",
      "  // toward continuation without repetition of incomplete text.\n",
      "  if (previousFinishReason === FinishReason.length) {\n",
      "    // If we see that we previously finished because of length, we assume that the current call is\n",
      "    // a continuation of an interrupted completion (max token length), and therefore we\n",
      "    // will not create a new cell and append text to the existing one instead\n",
      "    let cell = editor.notebook.cellAt(cellIndex);\n",
      "    currentKind = cell.kind;\n",
      "\n",
      "    // This is a workaround because normally we persist the role as cell metadata.\n",
      "    // However, we cannot read directly the metadata directly after write until the cell is out\n",
      "    // of edit mode, so we have to manually fix the role of the last cell in order to continue directly.\n",
      "    const userMessages = messages.filter((m) => m.role === \"user\");\n",
      "    userMessages[userMessages.length - 1].role = \"assistant\";\n",
      "\n",
      "    // we inject an extra message to force continuation without repetition\n",
      "    messages.push({\n",
      "      role: \"user\",\n",
      "      content: \"Continue. Don't repeat any text from your previous message.\",\n",
      "    });\n",
      "  }\n",
      "\n",
      "  const openAIApiKey = await getOpenAIApiKey();\n",
      "\n",
      "  if (!openAIApiKey) {\n",
      "    throw new Error(\"OpenAI API key is not set\");\n",
      "  }\n",
      "\n",
      "  const openai = new OpenAIApi(new Configuration({ apiKey: openAIApiKey }));\n",
      "\n",
      "  const tokenSource = axios.CancelToken.source();\n",
      "  token.onCancellationRequested(() => tokenSource.cancel());\n",
      "\n",
      "  const requestParams = {\n",
      "    model: model,\n",
      "    messages,\n",
      "    stream: true,\n",
      "    temperature: temperature,\n",
      "  };\n",
      "\n",
      "  output.appendLine(\"\\n\" + JSON.stringify(requestParams, undefined, 2) + \"\\n\");\n",
      "  progress.report({ increment: 1, message: SENDING_COMPLETION_REQUEST });\n",
      "\n",
      "  const response = await openai.createChatCompletion(requestParams, {\n",
      "    cancelToken: tokenSource.token,\n",
      "    responseType: \"stream\",\n",
      "  });\n",
      "\n",
      "  for await (let textToken of bufferWholeChunks(\n",
      "    streamChatCompletion(response, token)\n",
      "  )) {\n",
      "    // debug output of FinishReaseon\n",
      "    if (Object.values(FinishReason).includes(textToken as FinishReason)) {\n",
      "      switch (textToken) {\n",
      "        case FinishReason.length:\n",
      "          output.append(\"FINISH_REASON_LENGTH\" + \"\\n\");\n",
      "          break;\n",
      "        case FinishReason.contentFilter:\n",
      "          output.append(\"FINISH_REASON_CONTENTFILTER\" + \"\\n\");\n",
      "          break;\n",
      "        case FinishReason.stop:\n",
      "          output.append(\"FINISH_REASON_STOP\" + \"\\n\");\n",
      "          break;\n",
      "      }\n",
      "\n",
      "      const currentCell = editor.notebook.cellAt(cellIndex);\n",
      "      const text = currentCell.document.getText();\n",
      "\n",
      "      // we're wrapping up and may find out that the last cell only contains whitespaces or linesbreak.\n",
      "      // in that case, we retroactively removed that last empty cell\n",
      "      if (!/\\S/.test(text)) {\n",
      "        const edit = new WorkspaceEdit();\n",
      "        edit.set(currentCell.notebook.uri, [\n",
      "          NotebookEdit.deleteCells(\n",
      "            new NotebookRange(currentCell.index, currentCell.index + 1)\n",
      "          ),\n",
      "        ]);\n",
      "        await workspace.applyEdit(edit);\n",
      "      }\n",
      "\n",
      "      return textToken as FinishReason;\n",
      "    } else {\n",
      "      // Debug output of text\n",
      "      output.append(textToken.toString());\n",
      "    }\n",
      "\n",
      "    if (typeof textToken !== \"string\") {\n",
      "      throw new Error(\"Invalid state: unknown stream result: \" + textToken);\n",
      "    }\n",
      "\n",
      "    if (textToken.includes(pythonCodeBlockStart)) {\n",
      "      // we have yet to support polyglot notebooks, so for now we treat everything that isn't\n",
      "      // python as markdown. Still, we make a dedicated cell for that block.\n",
      "      currentKind = NotebookCellKind.Code;\n",
      "\n",
      "      cellIndex = await insertCell(editor, cellIndex, currentKind, \"python\");\n",
      "      textToken = textToken.replace(pythonCodeBlockStart, \"\");\n",
      "    } else if (\n",
      "      textToken.includes(codeBlockEnd) &&\n",
      "      currentKind === NotebookCellKind.Code\n",
      "    ) {\n",
      "      textToken = textToken.replace(codeBlockEnd, \"\");\n",
      "\n",
      "      // if after removing the backticks we still got some remaining that isn't linebreaks or whitespaces,\n",
      "      // we create a new markdown cell\n",
      "      currentKind = NotebookCellKind.Markup;\n",
      "      cellIndex = await insertCell(editor, cellIndex, currentKind, \"markdown\");\n",
      "    }\n",
      "\n",
      "    if (currentKind === undefined) {\n",
      "      // we assume we are just getting started with a first markdown cell\n",
      "      cellIndex = await insertCell(\n",
      "        editor,\n",
      "        cellIndex,\n",
      "        NotebookCellKind.Markup,\n",
      "        \"markdown\"\n",
      "      );\n",
      "      currentKind = NotebookCellKind.Markup;\n",
      "    }\n",
      "\n",
      "    // write token\n",
      "    await appendTextToCell(editor, cellIndex, textToken);\n",
      "\n",
      "    progress.report({ increment: 0.5, message: RECEIVING_TOKENS });\n",
      "  }\n",
      "\n",
      "  // We came to the end of the string without ever receiving a FinishReason from the API (or we have a bug). This is an invalid state.\n",
      "  throw new Error(\"Reached end of stream before receiving stop_reason\");\n",
      "}\n",
      "\n",
      "async function getOpenAIApiKey(): Promise<string> {\n",
      "  let openaiApiKey = workspace\n",
      "    .getConfiguration()\n",
      "    .get<string>(\"notebook-chatcompletion.openaiApiKey\");\n",
      "  if (!openaiApiKey) {\n",
      "    // Prompt the user to enter the API key\n",
      "    openaiApiKey = await window.showInputBox({\n",
      "      prompt: \"Enter your OpenAI API Key:\",\n",
      "      validateInput: (value) =>\n",
      "        value.trim().length > 0 ? null : \"API Key cannot be empty\",\n",
      "    });\n",
      "\n",
      "    // Save the API key to the extension settings\n",
      "    if (openaiApiKey) {\n",
      "      await workspace\n",
      "        .getConfiguration()\n",
      "        .update(\n",
      "          \"notebook-chatcompletion.openaiApiKey\",\n",
      "          openaiApiKey,\n",
      "          ConfigurationTarget.Global\n",
      "        );\n",
      "    } else {\n",
      "      // If the user didn't provide an API key, show an error message and return\n",
      "      window.showErrorMessage(\n",
      "        \"OpenAI API Key is required for Notebook ChatCompletion to work.\"\n",
      "      );\n",
      "      return \"\";\n",
      "    }\n",
      "  }\n",
      "\n",
      "  return openaiApiKey;\n",
      "}\n",
      " \n",
      "```\n",
      "\n",
      "\n",
      "File: '../../package.json'\n",
      "```\n",
      " {\n",
      "  \"name\": \"notebook-chatcompletion\",\n",
      "  \"displayName\": \"Jupyter Notebook ChatCompletion\",\n",
      "  \"description\": \"\",\n",
      "  \"version\": \"0.0.1\",\n",
      "  \"engines\": {\n",
      "    \"vscode\": \"^1.76.0\"\n",
      "  },\n",
      "  \"categories\": [\n",
      "    \"Notebooks\"\n",
      "  ],\n",
      "  \"activationEvents\": [\n",
      "    \"onNotebook:jupyter-notebook\"\n",
      "  ],\n",
      "  \"main\": \"./out/extension.js\",\n",
      "  \"contributes\": {\n",
      "    \"commands\": [\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.sendCellAndAbove\",\n",
      "        \"title\": \"Complete with this Cell and Above\",\n",
      "        \"icon\": \"$(comment-discussion)\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.sendCell\",\n",
      "        \"title\": \"Complete with this Cell\",\n",
      "        \"icon\": \"$(comment)\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.setTemperature\",\n",
      "        \"title\": \"Set Temperature\",\n",
      "        \"icon\": \"$(flame)\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.setModel\",\n",
      "        \"title\": \"Set Model\",\n",
      "        \"icon\": \"$(hubot)\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.setRoleAssistant\",\n",
      "        \"title\": \"Set Role to Assistant\",\n",
      "        \"icon\": \"$(hubot)\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.setRoleSystem\",\n",
      "        \"title\": \"Set Role to System\",\n",
      "        \"icon\": \"$(milestone)\"\n",
      "      }\n",
      "    ],\n",
      "    \"keybindings\": [\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.sendCellAndAbove\",\n",
      "        \"key\": \"ctrl+shift+enter\",\n",
      "        \"mac\": \"ctrl+cmd+enter\"\n",
      "      },\n",
      "      {\n",
      "        \"command\": \"notebook-chatcompletion.sendCell\",\n",
      "        \"key\": \"ctrl+shift+pagedown\",\n",
      "        \"mac\": \"ctrl+cmd+pagedown\"\n",
      "      }\n",
      "    ],\n",
      "    \"menus\": {\n",
      "      \"notebook/toolbar\": [\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.setTemperature\",\n",
      "          \"group\": \"navigation@1\"\n",
      "        },\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.setModel\",\n",
      "          \"group\": \"navigation@1\"\n",
      "        }\n",
      "      ],\n",
      "      \"notebook/cell/title\": [\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.sendCellAndAbove\",\n",
      "          \"group\": \"inline\"\n",
      "        },\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.sendCell\",\n",
      "          \"group\": \"inline\"\n",
      "        },\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.setRoleAssistant\",\n",
      "          \"group\": \"inline\"\n",
      "        },\n",
      "        {\n",
      "          \"command\": \"notebook-chatcompletion.setRoleSystem\",\n",
      "          \"group\": \"inline\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"configuration\": [\n",
      "      {\n",
      "        \"title\": \"Notebook ChatCompletion\",\n",
      "        \"properties\": {\n",
      "          \"notebook-chatcompletion.openaiApiKey\": {\n",
      "            \"type\": \"string\",\n",
      "            \"default\": \"\",\n",
      "            \"description\": \"OpenAI API Key for Notebook ChatCompletion\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"scripts\": {\n",
      "    \"vscode:prepublish\": \"npm run compile\",\n",
      "    \"compile\": \"tsc -p ./\",\n",
      "    \"watch\": \"tsc -watch -p ./\",\n",
      "    \"pretest\": \"npm run compile && npm run lint\",\n",
      "    \"lint\": \"eslint src --ext ts\",\n",
      "    \"test\": \"node ./out/test/runTest.js\"\n",
      "  },\n",
      "  \"devDependencies\": {\n",
      "    \"@types/glob\": \"^8.1.0\",\n",
      "    \"@types/mocha\": \"^10.0.1\",\n",
      "    \"@types/node\": \"16.x\",\n",
      "    \"@types/vscode\": \"^1.76.0\",\n",
      "    \"@typescript-eslint/eslint-plugin\": \"^5.56.0\",\n",
      "    \"@typescript-eslint/parser\": \"^5.56.0\",\n",
      "    \"@vscode/test-electron\": \"^2.3.0\",\n",
      "    \"eslint\": \"^8.36.0\",\n",
      "    \"glob\": \"^8.1.0\",\n",
      "    \"mocha\": \"^10.2.0\",\n",
      "    \"typescript\": \"^4.9.5\"\n",
      "  },\n",
      "  \"extensionDependencies\": [\n",
      "    \"ms-toolsai.jupyter\"\n",
      "  ],\n",
      "  \"dependencies\": {\n",
      "    \"openai\": \"^3.2.1\",\n",
      "    \"ws\": \"^8.13.0\"\n",
      "  }\n",
      "} \n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "def print_file_content(file_path: Path):\n",
    "    print(f\"\\n\\nFile: '{file_path}'\")\n",
    "    print(\"```\\n\",file_path.read_text(), \"\\n```\")\n",
    "\n",
    "def process_files(file_patterns: List[str]):\n",
    "    for pattern in file_patterns:\n",
    "        for file in Path().glob(pattern):\n",
    "            print_file_content(file)\n",
    "\n",
    "file_patterns = [\"../../src/*.ts\", \"../../package.json\"]\n",
    "process_files(file_patterns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please modify the implementation of the VSCode extension above so that all OpenAI client parameters can be configured by the user. Just like temperature and model, the parameters are expected to be saved and loaded from notebook metadata, and each parameter should have its own own dedicated command."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "Here's the modified implementation of the VSCode extension that allows users to configure all OpenAI client parameters. Each parameter has its own dedicated command, and the parameters are saved and loaded from the notebook metadata.\n",
    "\n",
    "First, update the `package.json` file to add new commands for each parameter:\n",
    "\n",
    "```json\n",
    "{\n",
    "  ...\n",
    "  \"contributes\": {\n",
    "    \"commands\": [\n",
    "      ...\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setTopP\",\n",
    "        \"title\": \"Set Top P\",\n",
    "        \"icon\": \"$(list-flat)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setN\",\n",
    "        \"title\": \"Set N\",\n",
    "        \"icon\": \"$(list-numbered)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setStream\",\n",
    "        \"title\": \"Set Stream\",\n",
    "        \"icon\": \"$(broadcast)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setMaxTokens\",\n",
    "        \"title\": \"Set Max Tokens\",\n",
    "        \"icon\": \"$(list-ordered)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setPresencePenalty\",\n",
    "        \"title\": \"Set Presence Penalty\",\n",
    "        \"icon\": \"$(pulse)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setFrequencyPenalty\",\n",
    "        \"title\": \"Set Frequency Penalty\",\n",
    "        \"icon\": \"$(pulse)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setLogitBias\",\n",
    "        \"title\": \"Set Logit Bias\",\n",
    "        \"icon\": \"$(graph)\"\n",
    "      },\n",
    "      {\n",
    "        \"command\": \"notebook-chatcompletion.setUser\",\n",
    "        \"title\": \"Set User\",\n",
    "        \"icon\": \"$(person)\"\n",
    "      }\n",
    "    ],\n",
    "    ...\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "Next, update the `src/extension.ts` file to add new functions for each command:\n",
    "\n",
    "```typescript\n",
    "import {\n",
    "  ...\n",
    "} from \"vscode\";\n",
    "import {\n",
    "  ...\n",
    "} from \"./cellUtils\";\n",
    "import { CompletionType } from \"./completionType\";\n",
    "import { FinishReason } from \"./finishReason\";\n",
    "import { bufferWholeChunks, streamChatCompletion } from \"./streamUtils\";\n",
    "import { UIProgress } from \"./uiProgress\";\n",
    "\n",
    "export async function activate(context: ExtensionContext) {\n",
    "  context.subscriptions.push(\n",
    "    ...\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setTopP\",\n",
    "      setTopP\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setN\",\n",
    "      setN\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setStream\",\n",
    "      setStream\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setMaxTokens\",\n",
    "      setMaxTokens\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setPresencePenalty\",\n",
    "      setPresencePenalty\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setFrequencyPenalty\",\n",
    "      setFrequencyPenalty\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setLogitBias\",\n",
    "      setLogitBias\n",
    "    )\n",
    "  );\n",
    "\n",
    "  context.subscriptions.push(\n",
    "    commands.registerCommand(\n",
    "      \"notebook-chatcompletion.setUser\",\n",
    "      setUser\n",
    "    )\n",
    "  );\n",
    "}\n",
    "\n",
    "...\n",
    "\n",
    "async function setTopP() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const topP = await window.showInputBox({\n",
    "    prompt: \"Enter the Top P value (0-1):\",\n",
    "    validateInput: (value) =>\n",
    "      parseFloat(value) >= 0 && parseFloat(value) <= 1\n",
    "        ? null\n",
    "        : \"Top P must be between 0 and 1\",\n",
    "  });\n",
    "\n",
    "  if (topP) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          top_p: parseFloat(topP),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "Continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "```typescript\n",
    "async function setN() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const n = await window.showInputBox({\n",
    "    prompt: \"Enter the N value (integer):\",\n",
    "    validateInput: (value) =>\n",
    "      parseInt(value) > 0 ? null : \"N must be a positive integer\",\n",
    "  });\n",
    "\n",
    "  if (n) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          n: parseInt(n),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setStream() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const stream = await window.showQuickPick([\"true\", \"false\"], {\n",
    "    placeHolder: \"Select the Stream value:\",\n",
    "  });\n",
    "\n",
    "  if (stream) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          stream: stream === \"true\",\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setMaxTokens() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const maxTokens = await window.showInputBox({\n",
    "    prompt: \"Enter the Max Tokens value (integer):\",\n",
    "    validateInput: (value) =>\n",
    "      parseInt(value) > 0 ? null : \"Max Tokens must be a positive integer\",\n",
    "  });\n",
    "\n",
    "  if (maxTokens) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          max_tokens: parseInt(maxTokens),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setPresencePenalty() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const presencePenalty = await window.showInputBox({\n",
    "    prompt: \"Enter the Presence Penalty value (0-1):\",\n",
    "    validateInput: (value) =>\n",
    "      parseFloat(value) >= 0 && parseFloat(value) <= 1\n",
    "        ? null\n",
    "        : \"Presence Penalty must be between 0 and 1\",\n",
    "  });\n",
    "\n",
    "  if (presencePenalty) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          presence_penalty: parseFloat(presencePenalty),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setFrequencyPenalty() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const frequencyPenalty = await window.showInputBox({\n",
    "    prompt: \"Enter the Frequency Penalty value (0-1):\",\n",
    "    validateInput: (value) =>\n",
    "      parseFloat(value) >= 0 && parseFloat(value) <= 1\n",
    "        ? null\n",
    "        : \"Frequency Penalty must be between 0 and 1\",\n",
    "  });\n",
    "\n",
    "  if (frequencyPenalty) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          frequency_penalty: parseFloat(frequencyPenalty),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setLogitBias() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const logitBias = await window.showInputBox({\n",
    "    prompt: \"Enter the Logit Bias value (JSON object):\",\n",
    "    validateInput: (value) => {\n",
    "      try {\n",
    "        JSON.parse(value);\n",
    "        return null;\n",
    "      } catch (error) {\n",
    "        return \"Logit Bias must be a valid JSON object\";\n",
    "      }\n",
    "    },\n",
    "  });\n",
    "\n",
    "  if (logitBias) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          logit_bias: JSON.parse(logitBias),\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "    await workspace.applyEdit(edit);\n",
    "  }\n",
    "}\n",
    "\n",
    "async function setUser() {\n",
    "  const editor = window.activeNotebookEditor!;\n",
    "  const user = await window.showInputBox({\n",
    "    prompt: \"Enter the User value (string):\",\n",
    "    validateInput: (value) =>\n",
    "      value.trim().length > 0 ? null : \"User value cannot be empty\",\n",
    "  });\n",
    "\n",
    "  if (user) {\n",
    "    const edit = new WorkspaceEdit();\n",
    "    edit.set(editor.notebook.uri, [\n",
    "      NotebookEdit.updateNotebookMetadata({\n",
    "        custom: {\n",
    "          ...editor.notebook.metadata.custom,\n",
    "          user: user,\n",
    "        },\n",
    "      }),\n",
    "    ]);\n",
    "        await workspace.applyEdit(edit);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "```typescript\n",
    "async function chatCompletion() {\n",
    "  ...\n",
    "  const topP = editor.notebook.metadata.custom?.top_p ?? 0.9;\n",
    "  const n = editor.notebook.metadata.custom?.n ?? 1;\n",
    "  const stream = editor.notebook.metadata.custom?.stream ?? false;\n",
    "  const maxTokens = editor.notebook.metadata.custom?.max_tokens ?? 4096;\n",
    "  const presencePenalty = editor.notebook.metadata.custom?.presence_penalty ?? 0;\n",
    "  const frequencyPenalty = editor.notebook.metadata.custom?.frequency_penalty ?? 0;\n",
    "  const logitBias = editor.notebook.metadata.custom?.logit_bias ?? {};\n",
    "  const user = editor.notebook.metadata.custom?.user ?? \"User\";\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "With these changes, the VSCode extension now allows users to configure all OpenAI client parameters. Each parameter has its own dedicated command, and the parameters are saved and loaded from the notebook metadata."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all these new commands to the \"notebook/cell/title\" menu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "assistant"
    ]
   },
   "source": [
    "To add all the new commands to the \"notebook/cell/title\" menu, update the `package.json` file by adding the new commands to the `menus` section:\n",
    "\n",
    "```json\n",
    "{\n",
    "  ...\n",
    "  \"contributes\": {\n",
    "    ...\n",
    "    \"menus\": {\n",
    "      \"notebook/cell/title\": [\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.chatCompletion\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"0_chatcompletion\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setModel\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setTemperature\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setTopP\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setN\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setStream\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setMaxTokens\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setPresencePenalty\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setFrequencyPenalty\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setLogitBias\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        },\n",
    "        {\n",
    "          \"command\": \"notebook-chatcompletion.setUser\",\n",
    "          \"when\": \"notebookType == chatcompletion\",\n",
    "          \"group\": \"1_parameters\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    ...\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "Now, all the new commands will be available in the \"notebook/cell/title\" menu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "model": "gpt-4",
 "nbformat": 4,
 "nbformat_minor": 2
}
